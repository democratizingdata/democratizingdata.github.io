---
title: "Our Approach"
layout: default
description: "Discover the machine learning algorithms, data validation processes, and methodologies we use to identify and track federal dataset usage in research publications."
---

<!-- Our Approach Hero Section -->
<section class="c-hero c-hero--dashboard">
    <div class="container">
        <div class="row align-items-center">
            <div class="col-lg-8">
                <div class="c-hero__content">
                    <div class="c-hero__category">
                        <span class="c-category-badge">METHODOLOGY</span>
                    </div>
                    <h1 class="c-hero__title">
                        Our Approach to
                        <span class="c-hero__title-highlight">Data Discovery</span>
                    </h1>
                    <p class="c-hero__description">
                        Discover the machine learning algorithms, data validation processes, and methodologies we use to identify and track federal dataset usage in research publications.
                    </p>
                    <div class="c-hero__actions">
                        <a href="#methodology" class="c-button c-button--primary">
                            Explore Methods
                            <svg class="c-button__icon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M7 17L17 7M17 7H7M17 7V17"/>
                            </svg>
                        </a>
                        <a href="#machine-learning" class="c-button c-button--secondary">
                            View Algorithms
                        </a>
                    </div>
                </div>
            </div>
            <div class="col-lg-5">
                <div class="c-hero__image">
                    <img src="{{ site.baseurl }}/assets/img/hero/data-analysis-workspace.jpg"
                         alt="Professional data analysis workspace with charts, graphs, and technical documentation"
                         class="img-fluid">
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Methodology Overview Section -->
<section class="c-content-section" id="methodology">
    <div class="container">
        <div class="c-content-section__header">
            <div class="c-category-badge">WORKFLOW OVERVIEW</div>
            <h2 class="c-content-section__title">Three-Stage Research Process</h2>
        </div>
        <div class="row">
            <div class="col-lg-8">
                <p>Our comprehensive approach involves three main workflow stages: identifying and finding datasets in publications through advanced machine learning; providing agency and researcher access to information through APIs, Jupyter Notebooks and researcher dashboards; and gathering feedback from the user community to continuously improve our methods.</p>

                <div class="c-feature-card">
                    <h3>How We Do It</h3>
                    <p>This project is made possible through the use of cutting-edge machine learning algorithms combined with expert human validation. Our team of expert reviewers validates all outputs to ensure that the results generated are accurate, reliable, and actionable for policy and research decisions.</p>
                </div>

                <div class="row">
                    <div class="col-md-4">
                        <div class="c-dataset-card c-dataset-card--blue">
                            <h4>üîç Process</h4>
                            <h5>Dataset Identification</h5>
                            <p class="c-dataset-card__description">Advanced machine learning algorithms scan millions of research publications to identify mentions and usage of federal datasets.</p>
                        </div>
                    </div>
                    <div class="col-md-4">
                        <div class="c-dataset-card c-dataset-card--green">
                            <h4>üìä Access</h4>
                            <h5>Data Dissemination</h5>
                            <p class="c-dataset-card__description">Provide researchers and agencies with accessible tools including APIs, dashboards, and interactive notebooks.</p>
                        </div>
                    </div>
                    <div class="col-md-4">
                        <div class="c-dataset-card c-dataset-card--purple">
                            <h4>üí¨ Feedback</h4>
                            <h5>Community Input</h5>
                            <p class="c-dataset-card__description">Continuous improvement through user feedback and expert validation to enhance accuracy and utility.</p>
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="col-lg-4">
                <div class="c-sidebar-card c-sidebar-card--blue">
                    <h4>Key Technologies</h4>
                    <ul class="c-feature-list">
                        <li>Natural Language Processing (NLP)</li>
                        <li>Deep Learning Models</li>
                        <li>Pattern Recognition</li>
                        <li>Entity Extraction</li>
                        <li>Sentence Context Analysis</li>
                        <li>Expert Validation Systems</li>
                    </ul>
                    
                    <h5>Research Impact</h5>
                    <p class="c-sidebar-card__description">Our methods help agencies understand how their data investments support scientific research and evidence-based policy making.</p>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Machine Learning Section -->
<section class="c-content-section c-content-section--gray" id="machine-learning">
    <div class="container">
        <div class="c-content-section__header">
            <div class="c-category-badge">TECHNICAL APPROACH</div>
            <h2 class="c-content-section__title">Machine Learning Algorithms</h2>
        </div>
        <div class="row">
            <div class="col-lg-8">
                <p>Three specialized models were developed using the best Machine Learning (ML) and Natural Language Processing (NLP) tools to support the identification of datasets within full-text publications. Each model brings unique strengths to our comprehensive detection system.</p>

                <div class="c-dataset-card c-dataset-card--blue">
                    <h3>üß† Model 1: Deep Learning - Sentence Context</h3>
                    <p class="c-dataset-card__description">A deep learning-based approach that learns what kind of sentences contain references to datasets. This model is the most robust to new datasets and evaluates all text within documents to understand contextual usage patterns.</p>
                    <ul class="c-feature-list">
                        <li><strong>Strength:</strong> Comprehensive text analysis</li>
                        <li><strong>Approach:</strong> Contextual sentence classification</li>
                        <li><strong>Coverage:</strong> Full document evaluation</li>
                    </ul>
                </div>

                <div class="c-dataset-card c-dataset-card--green">
                    <h3>üè∑Ô∏è Model 2: Deep Learning - Entity Names</h3>
                    <p class="c-dataset-card__description">A deep learning-based approach that extracts names of entities from text and classifies whether an entity represents a dataset. This model excels at identifying specific dataset names and acronyms.</p>
                    <ul class="c-feature-list">
                        <li><strong>Strength:</strong> Precise entity recognition</li>
                        <li><strong>Approach:</strong> Named entity extraction and classification</li>
                        <li><strong>Coverage:</strong> Dataset name identification</li>
                    </ul>
                </div>

                <div class="c-dataset-card c-dataset-card--purple">
                    <h3>üîç Model 3: Pattern Matching</h3>
                    <p class="c-dataset-card__description">A rule-based approach that searches for patterns in documents similar to a curated list of existing datasets. This model provides high precision for known dataset patterns and variations.</p>
                    <ul class="c-feature-list">
                        <li><strong>Strength:</strong> High precision matching</li>
                        <li><strong>Approach:</strong> Rule-based pattern recognition</li>
                        <li><strong>Coverage:</strong> Known dataset variations</li>
                    </ul>
                </div>

                <div class="c-feature-card">
                    <h4>Model Integration</h4>
                    <p>These three models work together in an ensemble approach, combining their individual strengths to achieve higher accuracy and coverage than any single model could provide alone. The integration allows us to capture both explicit dataset mentions and implicit usage patterns across diverse research domains.</p>
                </div>
            </div>
            
            <div class="col-lg-4">
                <div class="c-sidebar-card c-sidebar-card--yellow">
                    <h4>Model Performance</h4>
                    <p class="c-sidebar-card__description">Our ensemble approach achieves:</p>
                    <ul class="c-sidebar-card__list">
                        <li>High precision in dataset identification</li>
                        <li>Robust performance across domains</li>
                        <li>Scalable processing capabilities</li>
                        <li>Continuous learning from validation</li>
                    </ul>
                    
                    <h5>Training Data</h5>
                    <p class="c-sidebar-card__description">Models trained on millions of research publications with expert-validated dataset mentions across multiple scientific domains.</p>
                </div>
                
                <div class="c-sidebar-card c-sidebar-card--green">
                    <h5>Technical Stack</h5>
                    <ul class="c-sidebar-card__list">
                        <li>TensorFlow & PyTorch</li>
                        <li>BERT & Transformer Models</li>
                        <li>spaCy NLP Pipeline</li>
                        <li>Scikit-learn</li>
                        <li>Custom Neural Architectures</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Data Validation Section -->
<section class="c-content-section" id="data-validation">
    <div class="container">
        <div class="c-content-section__header">
            <div class="c-category-badge">QUALITY ASSURANCE</div>
            <h2 class="c-content-section__title">Data Validation Process</h2>
        </div>
        <div class="row">
            <div class="col-lg-8">
                <p>Each agency utilizes our validation tool to ensure that machine learning outputs are accurate and reliable. This human-in-the-loop approach combines automated detection with expert review to maintain high quality standards.</p>

                <div class="c-feature-card">
                    <h3>Validation Workflow</h3>
                    <p>The validation tool provides reviewers with snippets from actual publications where our models have identified potential dataset references. Each snippet contains a candidate phrase identified by the model, and expert validators determine if these snippets correctly refer to the target dataset.</p>
                </div>

                <div class="row">
                    <div class="col-md-6">
                        <div class="c-dataset-card c-dataset-card--blue">
                            <h4>üìã Review Process</h4>
                            <ul class="c-feature-list">
                                <li>Expert reviewers examine model outputs</li>
                                <li>Context snippets provide publication evidence</li>
                                <li>Binary validation: correct or incorrect</li>
                                <li>Feedback improves model performance</li>
                            </ul>
                        </div>
                    </div>
                    <div class="col-md-6">
                        <div class="c-dataset-card c-dataset-card--green">
                            <h4>üéØ Quality Metrics</h4>
                            <ul class="c-feature-list">
                                <li>Precision and recall tracking</li>
                                <li>Inter-reviewer agreement scores</li>
                                <li>Model confidence calibration</li>
                                <li>Continuous accuracy monitoring</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <h3>Validation Outcomes</h3>
                <p>The validation process delivers three key benefits:</p>
                <ol class="c-feature-list">
                    <li><strong>Model Performance Insights:</strong> Provides detailed understanding of how well our models identify datasets across different research domains and publication types.</li>
                    <li><strong>Related Dataset Discovery:</strong> Identifies other datasets used in conjunction with agency datasets, revealing research ecosystems and data integration patterns.</li>
                    <li><strong>Usage Pattern Analysis:</strong> Reveals how researchers utilize each agency's data, informing future data collection and dissemination strategies.</li>
                </ol>
            </div>
            
            <div class="col-lg-4">
                <div class="c-sidebar-card c-sidebar-card--purple">
                    <h4>Validation Benefits</h4>
                    <ul class="c-feature-list">
                        <li>Ensures output accuracy</li>
                        <li>Builds agency confidence</li>
                        <li>Improves model training</li>
                        <li>Discovers usage patterns</li>
                        <li>Identifies related datasets</li>
                    </ul>
                    
                    <h5>Expert Reviewers</h5>
                    <p class="c-sidebar-card__description">Our validation team includes domain experts, data scientists, and agency representatives who understand both technical and policy contexts.</p>
                </div>
                
                <div class="c-sidebar-card c-sidebar-card--yellow">
                    <h5>Continuous Improvement</h5>
                    <p class="c-sidebar-card__description">Validation feedback creates a continuous learning loop:</p>
                    <ul class="c-sidebar-card__list">
                        <li>Model retraining with validated examples</li>
                        <li>Algorithm refinement based on errors</li>
                        <li>Expansion to new dataset types</li>
                        <li>Enhanced pattern recognition</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Impact Section -->
<section class="c-content-section c-content-section--gray">
    <div class="container">
        <div class="c-info-card">
            <h4>Methodology Impact</h4>
            <p>Our comprehensive approach to dataset identification and validation has enabled federal agencies to better understand the research impact of their data investments. By combining cutting-edge machine learning with expert human validation, we provide reliable insights into how government data supports scientific discovery and evidence-based policy making.</p>
            <p>This methodology has been successfully applied across multiple agencies and research domains, demonstrating its versatility and effectiveness in tracking data usage patterns at scale. The continuous feedback loop between automated detection and expert validation ensures that our methods remain accurate and relevant as research practices evolve.</p>
        </div>
    </div>
</section>
